参考文章：https://zhuanlan.zhihu.com/p/636215898
 https://blog.csdn.net/m0_59164520/article/details/145322617

lora最新进展方向：
lora核心：低秩分解来模拟参数的改变量，从而以极小的参数量来实现大模型的间接训练。

1.降低参数数量
	Qlora
2.

Qlora, 量化模型（压缩）
AdaLoRA
DoRA
**MoE-LoRA**
O-LoRA / FedLoRA

![[Pasted image 20260102131620.png]]

现在LORA技术最新进展

![[Pasted image 20260102131902.png]]


## LORA调节层次的问题

 ![[Pasted image 20260102130310.png]]
这几种方法的区别
该方法的核心思想就是通过低秩分解来模拟参数的改变量，从而以极小的参数量来实现大模型的间接训练。
